{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Explanation of the intuition behind the KNN algorithm.\n\r\nThe K-Nearest Neighbors (K-NN) algorithm, also known as the lazy learning algorithm, is aclear and  simple supervised machine learning method for regression and classification. It assumes that new cases are similar to existing ones, placing them in the most similar category.\n\nThe K-NN algorithm stores all available data and classifies a new data point based on its similarity to the existing data. This means that when new data appears, the KNN algorithm can quickly classify it into a suitable category.  As a non-parametric and lazy learner, K-NN makes no assumptions upfront, storing the dataset and acting when it classifies. Applications include pattern recognition, data mining, and intrusion detectiong applications.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# Pseudocode of the algorithm.\n**Step-I:** Select the number K of neighbors.\r\n\r\n**Step-II:** Determine the Euclidean distance between K neighbors.\r\n\r\n**Step-III:** Take the K closest neighbors based on the Euclidean distance calculated.\r\n\r\n**Step-IV:** Count the number of data points in each category among these K neighbors.\r\n\r\n**Step-V:** Assign the new data points to the category with the greatest number of neighbors.\r\n\r\n**Step-VI:** Our model is complete.mplete.plete.\n\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# Implementation of the algorithm",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# Generate random data for 25 people\nnp.random.seed(42)\n\nrandom_weights = np.random.normal(loc=75, scale=5, size=25)\nrandom_heights = np.random.normal(loc=1.75, scale=0.1, size=25)\nrandom_genders = np.random.choice(['Male', 'Female'], size=25)\n\nrandom_data = {\n    'Weight': random_weights,\n    'Height': random_heights,\n    'Gender': random_genders\n}\n\n# Convert to DataFrame\ndf_random = pd.DataFrame(random_data)\n\n# Create and train the KNN model\nknn_model = KNeighborsClassifier(n_neighbors=3)\nknn_model.fit(df_random[['Weight', 'Height']], df_random['Gender'])\n\n# Add a new data point for prediction\nnew_data_point = {'Weight': [76], 'Height': [1.56]}\ndf_new = pd.DataFrame(new_data_point)\n\n# Make prediction on the new data point\nprediction = knn_model.predict(df_new)\n\n# Show the table of random data\nprint(\"Random Data Table:\")\nprint(df_random)\n\n# Show the prediction for the new data point\nprint(\"\\nPrediction for the New Data Point:\")\nprint(df_new)\nprint(f'Predicted Gender: {prediction[0]}')\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Random Data Table:\n       Weight    Height  Gender\n0   77.483571  1.761092    Male\n1   74.308678  1.634901    Male\n2   78.238443  1.787570    Male\n3   82.615149  1.689936    Male\n4   73.829233  1.720831    Male\n5   73.829315  1.689829    Male\n6   82.896064  1.935228    Male\n7   78.837174  1.748650    Male\n8   72.652628  1.644229  Female\n9   77.712800  1.832254    Male\n10  72.682912  1.627916  Female\n11  72.671351  1.770886  Female\n12  76.209811  1.554033  Female\n13  65.433599  1.617181    Male\n14  66.375411  1.769686    Male\n15  72.188562  1.823847    Male\n16  69.935844  1.767137    Male\n17  76.571237  1.738435  Female\n18  70.459880  1.719890    Male\n19  67.938481  1.602148    Male\n20  82.328244  1.678016    Male\n21  73.871118  1.703936    Male\n22  75.337641  1.855712    Male\n23  67.876259  1.784362  Female\n24  72.278086  1.573696    Male\n\nPrediction for the New Data Point:\n   Weight  Height\n0      76    1.56\nPredicted Gender: Female\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 30
    },
    {
      "cell_type": "markdown",
      "source": "# Loss function + Optimization function identification\nA lost function is used to measure the accurancy of a model`s prediction between the predicted output and the actual output for each training sample. So, knowing this, we can say that the K-Nearest Neighbors (KNN) algorithm does not involve a loss function or an optimization function, since it is an instance-based algorithm that does not adjust parameters by optimization.\n\nIn KNN, prediction is performed by finding the nearest neighbors based on a distance measure, such as Euclidean distance, and assigning a label based on the majority of votes (in classification) or calculating the mean (in regression) among those neighbors. There is neither a loss function that minimizes nor an optimization function that adjusts parameters, as in some other supervised learning algorithms.ngneighbors. There is neither a loss function that minimizes nor an optimization function that adjusts parameters, as in some other supervised learning algorithms.\n\nHowever we can calculate the accuracy of our predictions, down you will see an example of it. d learning \r\nalgorithms.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\n\n# Generate random data for 25 people\nnp.random.seed(42)\n\nrandom_weights = np.random.normal(loc=75, scale=5, size=25)\nrandom_heights = np.random.normal(loc=1.75, scale=0.1, size=25)\nrandom_genders = np.random.choice(['Male', 'Female'], size=25)\n\nrandom_data = {\n    'Weight': random_weights,\n    'Height': random_heights,\n    'Gender': random_genders\n}\n\n# Convert to DataFrame\ndf_random = pd.DataFrame(random_data)\n\n# Shuffle and split the data into training and test set\nX = df_random[['Weight', 'Height']]\nY = df_random['Gender']\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=42)\n\n# Convert to numpy arrays\nx_train = np.array(x_train)\ny_train = np.array(y_train)\nx_test = np.array(x_test)\ny_test = np.array(y_test)\n\n# Create and train the KNN model\nknn_model = KNeighborsClassifier(n_neighbors=3)\nknn_model.fit(x_train, y_train)\n\n# Make predictions on the test data\npredictions = knn_model.predict(x_test)\n\n# Evaluate the accuracy\naccuracy = np.mean(predictions == y_test)\n\n# Show the table of random data\nprint(\"Random Data Table:\")\nprint(df_random)\n\n# Show the predictions for the test data\nprint(\"\\nPredictions for the Test Data:\")\nprint(pd.DataFrame({'Weight': x_test[:, 0], 'Height': x_test[:, 1], 'Actual Gender': y_test, 'Predicted Gender': predictions}))\n\n# Show the accuracy\nprint(\"\\nAccuracy:\", accuracy)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Random Data Table:\n       Weight    Height  Gender\n0   77.483571  1.761092    Male\n1   74.308678  1.634901    Male\n2   78.238443  1.787570    Male\n3   82.615149  1.689936    Male\n4   73.829233  1.720831    Male\n5   73.829315  1.689829    Male\n6   82.896064  1.935228    Male\n7   78.837174  1.748650    Male\n8   72.652628  1.644229  Female\n9   77.712800  1.832254    Male\n10  72.682912  1.627916  Female\n11  72.671351  1.770886  Female\n12  76.209811  1.554033  Female\n13  65.433599  1.617181    Male\n14  66.375411  1.769686    Male\n15  72.188562  1.823847    Male\n16  69.935844  1.767137    Male\n17  76.571237  1.738435  Female\n18  70.459880  1.719890    Male\n19  67.938481  1.602148    Male\n20  82.328244  1.678016    Male\n21  73.871118  1.703936    Male\n22  75.337641  1.855712    Male\n23  67.876259  1.784362  Female\n24  72.278086  1.573696    Male\n\nPredictions for the Test Data:\n      Weight    Height Actual Gender Predicted Gender\n0  72.652628  1.644229        Female           Female\n1  69.935844  1.767137          Male             Male\n2  77.483571  1.761092          Male             Male\n\nAccuracy: 1.0\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 31
    }
  ]
}