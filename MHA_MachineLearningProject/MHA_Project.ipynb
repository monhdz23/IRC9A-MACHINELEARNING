{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "librerias"
      ],
      "metadata": {
        "id": "tISGTEWNroZS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NAfh7jGArm22"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import zipfile\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.cluster import KMeans\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Descrompimir el dataset"
      ],
      "metadata": {
        "id": "txQtKszzrr6U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zip_file_path = \"/content/IRND.zip\"\n",
        "extracted_dir = \"/content/IRND\"\n",
        "\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extracted_dir)"
      ],
      "metadata": {
        "id": "DoImHqg7rsGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "preparacion dataset"
      ],
      "metadata": {
        "id": "oQYerVPzrsXV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "# Ruta del directorio que contiene los archivos JSON\n",
        "data_dir = \"/content/IRND/outputs_2\"\n",
        "\n",
        "# Directorio de salida para los archivos modificados\n",
        "output_dir = \"/content/IRND/outputs_2_modified\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Número máximo de registros deseados\n",
        "max_num_records = 30\n",
        "\n",
        "for file_name in os.listdir(data_dir):\n",
        "    if file_name.endswith('.json'):\n",
        "        input_file_path = os.path.join(data_dir, file_name)\n",
        "        output_file_path = os.path.join(output_dir, file_name)\n",
        "\n",
        "        with open(input_file_path, 'r') as input_file:\n",
        "            data = json.load(input_file)\n",
        "\n",
        "        # Limitar a 30 registros\n",
        "        data['data'] = data['data'][:max_num_records]\n",
        "\n",
        "        # Ajustar longitud de 'angles', 'dists', 'counts_left', 'counts_right', y 'horn' a 8\n",
        "        for record in data['data']:\n",
        "            record['angles'] = record.get('angles', [])[:8]\n",
        "            record['dists'] = record.get('dists', [])[:8]\n",
        "            record['counts_left'] = record.get('counts_left', 0)\n",
        "            record['counts_right'] = record.get('counts_right', 0)\n",
        "            record['horn'] = record.get('horn', 0)\n",
        "\n",
        "        # Rellenar 'angles', 'dists' con datos similares si es necesario\n",
        "        for record in data['data']:\n",
        "            record['angles'] += [record['angles'][0]] * (8 - len(record['angles']))\n",
        "            record['dists'] += [record['dists'][0]] * (8 - len(record['dists']))\n",
        "\n",
        "        # Rellenar con registros vacíos si es necesario\n",
        "        while len(data['data']) < max_num_records:\n",
        "            data['data'].append({'direction': '', 'pose': {}, 'brake': 0, 'angles': [0.0] * 8, 'dists': [0.0] * 8, 'counts_left': 0, 'horn': 0, 'counts_right': 0})\n",
        "\n",
        "        # Guardar el archivo modificado\n",
        "        with open(output_file_path, 'w') as output_file:\n",
        "            json.dump(data, output_file, indent=2)\n",
        "\n",
        "print(\"Archivos modificados guardados en:\", output_dir)\n"
      ],
      "metadata": {
        "id": "SPMeWOVBrsmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizacion"
      ],
      "metadata": {
        "id": "5QzcuKgKrsyK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Ruta al directorio que contiene los archivos outputs_2\n",
        "outputs_2_dir = \"/content/IRND/outputs_2_modified\"\n",
        "\n",
        "# Leer algunos ejemplos de archivos JSON y mostrar información\n",
        "for i in range(1, 6):  # Visualizar información de los primeros 5 archivos\n",
        "    file_path = os.path.join(outputs_2_dir, f\"{i}.json\")\n",
        "    with open(file_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "        print(f\"Información del archivo {i}:\")\n",
        "        print(f\"Keys presentes: {list(data.keys())}\")\n",
        "        print(f\"Número de elementos en 'data': {len(data['data'])}\")\n",
        "        print(f\"Ejemplo de un elemento en 'data': {data['data'][0]}\")\n",
        "        print(\"\\n\" + \"-\"*40 + \"\\n\")\n"
      ],
      "metadata": {
        "id": "b9PeqRW9rs_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lectura de archivos JSON y preparación de datos"
      ],
      "metadata": {
        "id": "6Z9NVwxQrtQK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparar la lectura de outputs\n",
        "data_dir = \"/content/IRND\"\n",
        "output_dir = os.path.join(data_dir, 'outputs_2_modified')\n",
        "\n",
        "data_outputs_2 = []\n",
        "etiquetas_reales = []\n",
        "\n",
        "for file_name in os.listdir(output_dir):\n",
        "    if file_name.endswith('.json'):\n",
        "        file_path = os.path.join(output_dir, file_name)\n",
        "        try:\n",
        "            with open(file_path, 'r') as f:\n",
        "                current_data = json.load(f)\n",
        "                # Verificar la longitud de 'data' y rellenar si es necesario\n",
        "                while len(current_data['data']) < 30:\n",
        "                    current_data['data'].append(current_data['data'][0])\n",
        "                data_outputs_2.append(current_data)\n",
        "                etiquetas_reales.extend([file_name.split('_')[0]] * len(current_data['data']))\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"Error al leer {file_name}: {e}\")\n",
        "\n",
        "print(\"Número de archivos en outputs_2:\", len(data_outputs_2))"
      ],
      "metadata": {
        "id": "UfGVL1F-rtf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Características y etiquetas"
      ],
      "metadata": {
        "id": "NAgjz2y-sZyD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Características (X): Usar distancias como características\n",
        "X = [item['dists'] for data_output in data_outputs_2 for item in data_output['data']]\n",
        "\n",
        "# Codificación de etiquetas\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(etiquetas_reales)"
      ],
      "metadata": {
        "id": "WXeDIqSAsaL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aprendizaje no supervisado (K-Means)"
      ],
      "metadata": {
        "id": "vhP1pYueseOW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Aprendizaje No Supervisado (Ejemplo con K-Means)\n",
        "X_unsupervised = [item['dists'] for data_output in data_outputs_2 for item in data_output['data']]\n",
        "kmeans = KMeans(n_clusters=2, random_state=42)\n",
        "y_unsupervised = kmeans.fit_predict(X_unsupervised)"
      ],
      "metadata": {
        "id": "P6mZSYz0sesc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "División en conjuntos de entrenamiento y prueba para aprendizaje supervisado"
      ],
      "metadata": {
        "id": "iJH2HK95skNE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# División en Conjuntos de Entrenamiento y Prueba para aprendizaje supervisado\n",
        "X_train_supervised, X_test_supervised, y_train_encoded_supervised, y_test_encoded_supervised = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)\n"
      ],
      "metadata": {
        "id": "fIvkvsrKsj0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entrenamiento del modelo supervisado y persistencia del modelo"
      ],
      "metadata": {
        "id": "roBe-Pv-sogB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenar el modelo supervisado\n",
        "model_supervised = DecisionTreeClassifier(random_state=42)\n",
        "model_supervised.fit(X_train_supervised, y_train_encoded_supervised)\n",
        "\n",
        "# Guardar el modelo entrenado\n",
        "joblib.dump(model_supervised, model_path)\n",
        "print(\"Modelo entrenado guardado con éxito.\")"
      ],
      "metadata": {
        "id": "TpdWwZEcsost"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluación del modelo supervisado"
      ],
      "metadata": {
        "id": "JcSpVrqAss1r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluación del Modelo Supervisado\n",
        "y_pred_supervised = model_supervised.predict(X_test_supervised)\n",
        "accuracy_supervised = accuracy_score(y_test_encoded_supervised, y_pred_supervised)\n",
        "conf_matrix_supervised = confusion_matrix(y_test_encoded_supervised, y_pred_supervised, labels=le.transform(etiquetas_reales))\n"
      ],
      "metadata": {
        "id": "m-nylFZXstG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Acciones según la categoría del aprendizaje no supervisado"
      ],
      "metadata": {
        "id": "8y-pNexAsxzL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Acciones según Categoría del Aprendizaje No Supervisado\n",
        "points_unsupervised = 0\n",
        "choca_repetidamente = 0\n",
        "\n",
        "for features, true_label_unsupervised, true_label_supervised in zip(X_unsupervised, y_unsupervised, y_test_encoded_supervised):\n",
        "    decision_unsupervised = kmeans.predict([features])[0]\n",
        "\n",
        "    if decision_unsupervised == 0:  # RODEAR\n",
        "        print(\"RODEAR - Acción de rodear\")\n",
        "        if choca_repetidamente > 2:\n",
        "            decision_unsupervised = 1  # Cambiar a RETROCEDER\n",
        "            choca_repetidamente = 0\n",
        "        else:\n",
        "            choca_repetidamente += 1\n",
        "    else:  # RETROCEDER\n",
        "        print(\"RETROCEDER - Acción de retroceder y doblar a la derecha\")\n",
        "        choca_repetidamente = 0\n",
        "\n",
        "    decision_supervised = model_supervised.predict([features])[0]\n",
        "    if decision_supervised == true_label_supervised:\n",
        "        points_unsupervised += 10\n",
        "    else:\n",
        "        points_unsupervised -= 20\n"
      ],
      "metadata": {
        "id": "_CVEb8M6syCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resultados finales"
      ],
      "metadata": {
        "id": "fy9_ygWUs2gm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nResultados del Modelo Supervisado:\")"
      ],
      "metadata": {
        "id": "Sq_UrXg0s4Rl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Accuracy (Supervised): {accuracy_supervised}')"
      ],
      "metadata": {
        "id": "c0TYorIXs56K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Matriz de Confusión (Supervised):\")"
      ],
      "metadata": {
        "id": "jTgdV9k5s6HG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(conf_matrix_supervised)"
      ],
      "metadata": {
        "id": "nqx4g7zHs6aU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Puntos finales (Supervised): {points_unsupervised}')"
      ],
      "metadata": {
        "id": "rzmvaGKas6nq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "C"
      ],
      "metadata": {
        "id": "rhPmMHXQtdrd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#librerias\n",
        "\n",
        "import os\n",
        "import json\n",
        "import zipfile\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.cluster import KMeans\n",
        "import joblib\n",
        "\n",
        "#Descrompimir el dataset\n",
        "\n",
        "zip_file_path = \"/content/IRND.zip\"\n",
        "extracted_dir = \"/content/IRND\"\n",
        "\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extracted_dir)\n",
        "\n",
        "#preparacion dataset\n",
        "\n",
        "import os\n",
        "import json\n",
        "\n",
        "# Ruta del directorio que contiene los archivos JSON\n",
        "data_dir = \"/content/IRND/outputs_2\"\n",
        "\n",
        "# Directorio de salida para los archivos modificados\n",
        "output_dir = \"/content/IRND/outputs_2_modified\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Número máximo de registros deseados\n",
        "max_num_records = 30\n",
        "\n",
        "for file_name in os.listdir(data_dir):\n",
        "    if file_name.endswith('.json'):\n",
        "        input_file_path = os.path.join(data_dir, file_name)\n",
        "        output_file_path = os.path.join(output_dir, file_name)\n",
        "\n",
        "        with open(input_file_path, 'r') as input_file:\n",
        "            data = json.load(input_file)\n",
        "\n",
        "        # Limitar a 30 registros\n",
        "        data['data'] = data['data'][:max_num_records]\n",
        "\n",
        "        # Ajustar longitud de 'angles', 'dists', 'counts_left', 'counts_right', y 'horn' a 8\n",
        "        for record in data['data']:\n",
        "            record['angles'] = record.get('angles', [])[:8]\n",
        "            record['dists'] = record.get('dists', [])[:8]\n",
        "            record['counts_left'] = record.get('counts_left', 0)\n",
        "            record['counts_right'] = record.get('counts_right', 0)\n",
        "            record['horn'] = record.get('horn', 0)\n",
        "\n",
        "        # Rellenar 'angles', 'dists' con datos similares si es necesario\n",
        "        for record in data['data']:\n",
        "            record['angles'] += [record['angles'][0]] * (8 - len(record['angles']))\n",
        "            record['dists'] += [record['dists'][0]] * (8 - len(record['dists']))\n",
        "\n",
        "        # Rellenar con registros vacíos si es necesario\n",
        "        while len(data['data']) < max_num_records:\n",
        "            data['data'].append({'direction': '', 'pose': {}, 'brake': 0, 'angles': [0.0] * 8, 'dists': [0.0] * 8, 'counts_left': 0, 'horn': 0, 'counts_right': 0})\n",
        "\n",
        "        # Guardar el archivo modificado\n",
        "        with open(output_file_path, 'w') as output_file:\n",
        "            json.dump(data, output_file, indent=2)\n",
        "\n",
        "print(\"Archivos modificados guardados en:\", output_dir)\n",
        "\n",
        "#Visualizacion\n",
        "\n",
        "import os\n",
        "\n",
        "# Ruta al directorio que contiene los archivos outputs_2\n",
        "outputs_2_dir = \"/content/IRND/outputs_2_modified\"\n",
        "\n",
        "# Leer algunos ejemplos de archivos JSON y mostrar información\n",
        "for i in range(1, 6):  # Visualizar información de los primeros 5 archivos\n",
        "    file_path = os.path.join(outputs_2_dir, f\"{i}.json\")\n",
        "    with open(file_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "        print(f\"Información del archivo {i}:\")\n",
        "        print(f\"Keys presentes: {list(data.keys())}\")\n",
        "        print(f\"Número de elementos en 'data': {len(data['data'])}\")\n",
        "        print(f\"Ejemplo de un elemento en 'data': {data['data'][0]}\")\n",
        "        print(\"\\n\" + \"-\"*40 + \"\\n\")\n",
        "\n",
        "#Lectura de archivos JSON y preparación de datos\n",
        "\n",
        "# Preparar la lectura de outputs\n",
        "data_dir = \"/content/IRND\"\n",
        "output_dir = os.path.join(data_dir, 'outputs_2_modified')\n",
        "\n",
        "data_outputs_2 = []\n",
        "etiquetas_reales = []\n",
        "\n",
        "for file_name in os.listdir(output_dir):\n",
        "    if file_name.endswith('.json'):\n",
        "        file_path = os.path.join(output_dir, file_name)\n",
        "        try:\n",
        "            with open(file_path, 'r') as f:\n",
        "                current_data = json.load(f)\n",
        "                # Verificar la longitud de 'data' y rellenar si es necesario\n",
        "                while len(current_data['data']) < 30:\n",
        "                    current_data['data'].append(current_data['data'][0])\n",
        "                data_outputs_2.append(current_data)\n",
        "                etiquetas_reales.extend([file_name.split('_')[0]] * len(current_data['data']))\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"Error al leer {file_name}: {e}\")\n",
        "\n",
        "print(\"Número de archivos en outputs_2:\", len(data_outputs_2))\n",
        "\n",
        "#Características y etiquetas\n",
        "\n",
        "# Características (X): Usar distancias como características\n",
        "X = [item['dists'] for data_output in data_outputs_2 for item in data_output['data']]\n",
        "\n",
        "# Codificación de etiquetas\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(etiquetas_reales)\n",
        "\n",
        "#Aprendizaje no supervisado (K-Means)\n",
        "\n",
        "# Aprendizaje No Supervisado (Ejemplo con K-Means)\n",
        "X_unsupervised = [item['dists'] for data_output in data_outputs_2 for item in data_output['data']]\n",
        "kmeans = KMeans(n_clusters=2, random_state=42)\n",
        "y_unsupervised = kmeans.fit_predict(X_unsupervised)\n",
        "\n",
        "#División en conjuntos de entrenamiento y prueba para aprendizaje supervisado\n",
        "\n",
        "# División en Conjuntos de Entrenamiento y Prueba para aprendizaje supervisado\n",
        "X_train_supervised, X_test_supervised, y_train_encoded_supervised, y_test_encoded_supervised = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)\n",
        "\n",
        "#Entrenamiento del modelo supervisado y persistencia del modelo\n",
        "\n",
        "# Entrenar el modelo supervisado\n",
        "model_supervised = DecisionTreeClassifier(random_state=42)\n",
        "model_supervised.fit(X_train_supervised, y_train_encoded_supervised)\n",
        "\n",
        "# Guardar el modelo entrenado\n",
        "joblib.dump(model_supervised, model_path)\n",
        "print(\"Modelo entrenado guardado con éxito.\")\n",
        "\n",
        "#Evaluación del modelo supervisado\n",
        "\n",
        "# Evaluación del Modelo Supervisado\n",
        "y_pred_supervised = model_supervised.predict(X_test_supervised)\n",
        "accuracy_supervised = accuracy_score(y_test_encoded_supervised, y_pred_supervised)\n",
        "conf_matrix_supervised = confusion_matrix(y_test_encoded_supervised, y_pred_supervised, labels=le.transform(etiquetas_reales))\n",
        "\n",
        "#Acciones según la categoría del aprendizaje no supervisado\n",
        "\n",
        "# Acciones según Categoría del Aprendizaje No Supervisado\n",
        "points_unsupervised = 0\n",
        "choca_repetidamente = 0\n",
        "\n",
        "for features, true_label_unsupervised, true_label_supervised in zip(X_unsupervised, y_unsupervised, y_test_encoded_supervised):\n",
        "    decision_unsupervised = kmeans.predict([features])[0]\n",
        "\n",
        "    if decision_unsupervised == 0:  # RODEAR\n",
        "        print(\"RODEAR - Acción de rodear\")\n",
        "        if choca_repetidamente > 2:\n",
        "            decision_unsupervised = 1  # Cambiar a RETROCEDER\n",
        "            choca_repetidamente = 0\n",
        "        else:\n",
        "            choca_repetidamente += 1\n",
        "    else:  # RETROCEDER\n",
        "        print(\"RETROCEDER - Acción de retroceder y doblar a la derecha\")\n",
        "        choca_repetidamente = 0\n",
        "\n",
        "    decision_supervised = model_supervised.predict([features])[0]\n",
        "    if decision_supervised == true_label_supervised:\n",
        "        points_unsupervised += 10\n",
        "    else:\n",
        "        points_unsupervised -= 20\n",
        "\n",
        "#Resultados finales\n",
        "\n",
        "print(\"\\nResultados del Modelo Supervisado:\")\n",
        "\n",
        "print(f'Accuracy (Supervised): {accuracy_supervised}')\n",
        "\n",
        "print(\"Matriz de Confusión (Supervised):\")\n",
        "\n",
        "print(conf_matrix_supervised)\n",
        "\n",
        "print(f'Puntos finales (Supervised): {points_unsupervised}')"
      ],
      "metadata": {
        "id": "enB0m7aztdJ-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}